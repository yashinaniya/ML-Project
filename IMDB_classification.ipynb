{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdjdJKR9CZ+b84C6Tvqfs3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashinaniya/ML-Project/blob/master/IMDB_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeYBCKW30Oy"
      },
      "source": [
        "# Run this to ensure TensorFlow 2.x is used\r\n",
        "try:\r\n",
        "  # %tensorflow_version only exists in Colab.\r\n",
        "  %tensorflow_version 2.x\r\n",
        "except Exception:\r\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFNfjERR4NGL"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "imdb_dataset = tf.keras.datasets.imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU1WeSn8461i",
        "outputId": "729715dd-6a09-4812-c16b-38eef5ff7b56"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = imdb_dataset.load_data(num_words=10000)\r\n",
        "print(x_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        " \r\n",
        "print(x_test.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE-m5ZbQCRrT"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY1FzxRQCii5"
      },
      "source": [
        "data = np.concatenate((x_train, x_test), axis=0)\r\n",
        "targets = np.concatenate((y_train, y_test), axis=0)\r\n",
        "def vectorize(sequences, dimension = 10000):\r\n",
        " results = np.zeros((len(sequences), dimension))\r\n",
        " for i, sequence in enumerate(sequences):\r\n",
        "  results[i, sequence] = 1\r\n",
        " return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiUb2eBCIMUR"
      },
      "source": [
        "data = vectorize(data)\r\n",
        "targets = np.array(targets).astype(\"float32\")\r\n",
        "test_x = data[:10000]\r\n",
        "test_y = targets[:10000]\r\n",
        "train_x = data[10000:]\r\n",
        "train_y = targets[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORGsazrlIRZw"
      },
      "source": [
        "model = tf.keras.Sequential([\r\n",
        "    tf.keras.layers.Dense(50, activation = \"relu\", input_shape=(10000, )),\r\n",
        "    # Hidden - Layers\r\n",
        "    tf.keras.layers.Dropout(0.3, noise_shape=None, seed=None),\r\n",
        "    tf.keras.layers.Dense(50, activation = \"relu\"),\r\n",
        "    tf.keras.layers.Dropout(0.2, noise_shape=None, seed=None),\r\n",
        "    tf.keras.layers.Dense(50, activation = \"relu\"),\r\n",
        "    #output layer\r\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kxrmc9RJdcB",
        "outputId": "af2ca422-6c89-408c-e175-50dd0a9b565f"
      },
      "source": [
        "results = model.fit(\r\n",
        " train_x, train_y,\r\n",
        " epochs= 2,\r\n",
        " batch_size = 500,\r\n",
        " validation_data = (test_x, test_y)\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "80/80 [==============================] - 5s 56ms/step - loss: 0.5399 - accuracy: 0.7104 - val_loss: 0.2616 - val_accuracy: 0.8942\n",
            "Epoch 2/2\n",
            "80/80 [==============================] - 3s 42ms/step - loss: 0.2156 - accuracy: 0.9194 - val_loss: 0.2675 - val_accuracy: 0.8943\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}